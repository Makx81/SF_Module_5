# Проект 5. Выбираем авто выгодно

### Описание модуля  
Вы работаете в компании, которая занимается продажей автомобилей с пробегом в Москве. 
Основная задача компании и её менеджеров — максимально быстро находить выгодные предложения (проще говоря, купить ниже рынка, а продать дороже рынка).

Руководство компании просит вашу команду создать модель, которая будет предсказывать стоимость автомобиля по его характеристикам.
Если такая модель будет работать хорошо, то вы сможете быстро выявлять выгодные предложения (когда желаемая цена продавца ниже предсказанной рыночной цены). 
Это значительно ускорит работу менеджеров и повысит прибыль компании.   

***Что мы будем делать?***  
- Проведем разведывательный анализ данных тестовой выборки.
- Создадим парсер для сбора данных тренировочной выборки.
- Напишем модель, которая будет предсказывать стоимость автомобиля по его характеристикам. 


### Какой кейс решаем?
Данный бизнес-кейс является аналогом существующего сервиса оценки стоимости автомобиля на сайте Auto.ru.
Проект выполнялся в рамках соревнования на kaggle.com в качестве учебного для специализации Data Science школы SkillFactory.

**Метрика качества**
Результаты оцениваются по средней относительной ошибке прогноза (Mean Absolute Percentage Error или MAPE).

### Этапы работы над проектом  
1. Разведывательный анализ (EDA) для тестового датасета.
Проведённый разведовательный анализ позволил подробно ознакомиться с датасетом, благодаря нему были определены данные, которые требовалось собрать для обучения модели.

2. Парсинг данных.
В качестве источника данных был выбран сайт auto.ru. Проведенный EDA тестовой выборки позволил сузить область поиска до автомобилей марки BMW. 
Кроме того, был обозначен круг искомых характеристик автомобилей. Сбор данных осуществлялся при помощи библиотеки requests. 
Сайт auto.ru формирует файл json по запросу пользователя. Работа с этим файлом велась при помощи библиотеки json.

3. Разведывательный анализ (EDA) для тренировочного датасета.

4. Построение базовой модели
В качестве базовой модели использовалась регрессионная модель CatBoostRegressor из библиотеки CatBoost от Yandex, которая умеет работать с категориальными признаками. 
Для того, чтобы избежать возможного переобучения и улучшить качество предсказания использовался Blending, т.е. выполнялось обучение модели на 5 фолдах, с дальнейшим объединением предсказаний от каждой модели.

5. Стэкинг.
Для стекинга использовалась библиотека vecstack и такие модели как RandomForestRegressor, ExtraTreesRegressor, LinearRegression, принимающие на вход лишь числовые переменные и не умеющие работать с категориальными, поэтому изначально выполнялось преобразование категориальных признаков.

Первые модели представляли первый уровень, а линейная регрессия была выбрана моделью второго уровня. Нами была рассмотрена также модель KNeighborsRegressor, но её использование в стекинге не дало улучшения. 
Перед процедурой стекинга, были подобраны оптимальные гиперпараметры для каждой из моделей. 

6. AutoML.
Однако лучшие результаты были получены для модели BestSingleModelRegressor из библиотеки AutoML.

Применение AutoML позволило улучшить результат с baseline 11.30 до 8.79

